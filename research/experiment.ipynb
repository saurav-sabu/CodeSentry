{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from git import Repo\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir repo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repo.clone_from(\"https://github.com/saurav-sabu/MediSage\",to_path=\"repo_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    \"repo_data/\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON,parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'repo_data\\\\app.py', 'language': <Language.PYTHON: 'python'>}, page_content='from flask import Flask, request, jsonify, render_template\\nfrom src.helper import *\\nfrom langchain_pinecone import PineconeVectorStore\\nfrom langchain.chains import create_retrieval_chain, create_history_aware_retriever\\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\\nfrom src.prompt import *\\nfrom langchain_core.messages import *\\nimport os\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\napp = Flask(__name__)\\n\\nembedding = initialize_embedding()\\n\\ndocsearch = PineconeVectorStore.from_existing_index(\\n    index_name=\"medisage\",\\n    embedding=embedding\\n)\\n\\nretriever = docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})\\n\\nchat_history = []\\n\\nmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\\n\\ncontextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\\\\nwhich might reference context in the chat history, formulate a standalone question \\\\\\nwhich can be understood without the chat history. Do NOT answer the question, \\\\\\njust reformulate it if needed and otherwise return it as is.\"\"\"\\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", contextualize_q_system_prompt),\\n        MessagesPlaceholder(\"chat_history\"),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\n\\nhistory_aware_retriever = create_history_aware_retriever(\\n    model, retriever, contextualize_q_prompt\\n)\\n\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", system_prompt),\\n        MessagesPlaceholder(\"chat_history\"),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\n\\nquestion_answer_chain = create_stuff_documents_chain(model,prompt)\\nrag_chain = create_retrieval_chain(history_aware_retriever,question_answer_chain)\\n\\n@app.route(\"/\")\\ndef index():\\n    return render_template(\"index.html\")\\n\\n@app.route(\"/ask\",methods=[\"GET\",\"POST\"])\\ndef ask():\\n    if request.method == \"POST\":\\n        question = request.form[\"chatInput\"]\\n        response = rag_chain.invoke({\"input\": question,\"chat_history\":chat_history})\\n        chat_history.extend([HumanMessage(content=question), response[\"answer\"]])\\n        \\n        # Extract the actual response text\\n        # Adjust this based on your exact response structure\\n        response_text = response.get(\\'answer\\', str(response))\\n        \\n        return jsonify({\"response\": response_text})\\n    return jsonify({\"response\": \"Please send a POST request with a question\"})\\n\\n\\nif __name__ == \"__main__\":\\n    app.run(host=\"0.0.0.0\",port=8080,debug=True)'),\n",
       " Document(metadata={'source': 'repo_data\\\\setup.py', 'language': <Language.PYTHON: 'python'>}, page_content='from setuptools import setup, find_packages\\n\\nsetup(\\n    name=\"MediSage\",\\n    version=\"0.1\",\\n    description=\"A chatbot for medical assistance\",\\n    author=\"Saurav Sabu\",\\n    author_email=\"saurav.sabu9@gmail.com\",\\n    packages=find_packages(),\\n    install_requires=[]\\n)'),\n",
       " Document(metadata={'source': 'repo_data\\\\store_index.py', 'language': <Language.PYTHON: 'python'>}, page_content='from src.helper import load_pdf_file, text_splitting, initialize_embedding\\nfrom dotenv import load_dotenv\\nfrom pinecone.grpc import PineconeGRPC as Pinecone\\nfrom pinecone import ServerlessSpec\\nfrom langchain_pinecone import PineconeVectorStore\\n\\nload_dotenv()\\n\\nextracted_data = load_pdf_file(\"data/medical_data.pdf\")\\nchunks = text_splitting(extracted_data)\\nembedding = initialize_embedding()\\n\\npc = Pinecone()\\n\\nindex_name = \"medisage\"\\n\\npc.create_index(\\n    name=index_name,\\n    dimension=768, # Replace with your model dimensions\\n    metric=\"cosine\", # Replace with your model metric\\n    spec=ServerlessSpec(\\n        cloud=\"aws\",\\n        region=\"us-east-1\"\\n    ) \\n)\\n\\ndocsearch = PineconeVectorStore.from_documents(\\n    documents=chunks,\\n    embedding=embedding,\\n    index_name=index_name,\\n)'),\n",
       " Document(metadata={'source': 'repo_data\\\\template.py', 'language': <Language.PYTHON: 'python'>}, page_content='import os\\nfrom pathlib import Path\\nimport logging\\n\\nlogging.basicConfig(level=logging.INFO, format=\\'%(asctime)s - %(levelname)s - %(message)s\\')\\n\\nlist_of_files = [\\n    \"src/__init__.py\",\\n    \"src/helper.py\",\\n    \"src/prompt.py\",\\n    \".env\",\\n    \"requirements.txt\",\\n    \"setup.py\",\\n    \"app.py\",\\n    \"research/experiment.ipynb\"\\n]\\n\\nfor filepath in list_of_files:\\n    filepath = Path(filepath)\\n\\n    filedir,filename = os.path.split(filepath)\\n\\n    if filedir != \"\":\\n        os.makedirs(filedir,exist_ok=True)\\n        logging.info(f\"Created directory: {filedir}\")\\n\\n    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\\n        with open(filepath, \\'w\\') as f:\\n            logging.info(f\"Created file: {filepath}\")\\n            pass\\n    else:\\n        logging.info(f\"File already exists: {filename}\")\\n'),\n",
       " Document(metadata={'source': 'repo_data\\\\src\\\\helper.py', 'language': <Language.PYTHON: 'python'>}, page_content='from langchain_text_splitters import RecursiveCharacterTextSplitter\\nfrom langchain_community.document_loaders import PyPDFLoader\\nfrom langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\\n\\ndef load_pdf_file(file_path):\\n    documents = PyPDFLoader(file_path).load()\\n    return documents\\n\\ndef text_splitting(extracted_data):\\n    splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\\n    chunks = splitter.split_documents(extracted_data)\\n    return chunks\\n\\ndef initialize_embedding():\\n    embedding = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\\n    return embedding'),\n",
       " Document(metadata={'source': 'repo_data\\\\src\\\\prompt.py', 'language': <Language.PYTHON: 'python'>}, page_content='\\n\\nsystem_prompt = \"\"\"\\nYou are MediSage, an AI-powered virtual medical assistant trained to provide general healthcare information, symptom explanations, and wellness guidance. You do not provide medical diagnoses or prescribe medications. Your primary role is to assist users with evidence-based health information while encouraging them to seek professional medical attention when necessary.\\n\\n###**Context:**\\n\\'{context}\\'\\n\\n### **Guidelines:**\\n1. **Professional & Empathetic** – Respond with medical accuracy while maintaining a compassionate tone.\\n2. **User-Friendly Language** – Explain medical terms in simple, easy-to-understand language.\\n3. **Advisory Role** – Provide general health insights, but never diagnose or prescribe treatment.\\n4. **Encourage Professional Consultation** – If a query requires a diagnosis, recommend consulting a healthcare professional.\\n5. **Ethical & Safe** – Avoid misinformation, medical treatments, or personal health predictions.\\n\\n### **Capabilities:**\\n✔ Explain symptoms and common conditions  \\n✔ Provide first-aid and general wellness advice  \\n✔ Suggest preventive healthcare measures  \\n✔ Explain medical terms, tests, and procedures  \\n✔ Offer insights on diet, fitness, and mental well-being  \\n\\n### **Limitations:**\\n✖ Cannot provide personalized diagnoses or treatments  \\n✖ Cannot prescribe medications or recommend dosages  \\n✖ Cannot replace professional medical advice  \\n\\n### **Example Interactions:**\\n\\n**User:** \"I have a sore throat and mild fever. What should I do?\"  \\n**MediSage:** \"A sore throat and mild fever can be caused by viral infections like the common cold. Stay hydrated, rest well, and consider warm fluids like herbal tea. If symptoms persist for more than 3 days or worsen, consult a doctor.\"\\n\\n**User:** \"Can I take aspirin for my headache?\"  \\n**MediSage:** \"I cannot recommend specific medications, but you may try resting in a quiet room, staying hydrated, or using a cold compress. If the headache is severe or persistent, consult a healthcare professional.\"\\n\\n**User:** \"What are the symptoms of diabetes?\"  \\n**MediSage:** \"Common symptoms of diabetes include increased thirst, frequent urination, fatigue, and blurred vision. If you experience these symptoms, it is advisable to consult a doctor for proper evaluation.\"\\n\\nAlways provide clear, safe, and non-diagnostic responses, prioritizing user well-being.\\n\"\"\"\\n'),\n",
       " Document(metadata={'source': 'repo_data\\\\src\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}, page_content='')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.from_documents(chunks,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.save_local(\"faiss-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an advanced AI with expert-level understanding of all programming languages, frameworks, \"\n",
    "    \"and best practices. You have access to the entire codebase provided by the user and can analyze it in depth. \"\n",
    "    \"Your role is to assist the user by answering queries related to the code, explaining functionalities, \"\n",
    "    \"suggesting improvements, debugging issues, and providing best practices. \"\n",
    "    \"Ensure your responses are clear, concise, and technically accurate. \"\n",
    "    \"If additional context is required, ask the user for clarification.\\n\\n\"\n",
    "    \"Here is the provided code:\\n + {context}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The embedding model being used is \"models/text-embedding-004\" from Google Generative AI, as initialized in the `initialize_embedding` function:\\n\\n```python\\ndef initialize_embedding():\\n    embedding = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\\n    return embedding\\n```'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":\"What embedding model is being used\"})[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
